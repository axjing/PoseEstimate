{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab_train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"_mqWFc0zemkl"},"source":["# Set TensorFlow version to 1.x\n","%tensorflow_version 1.x\n","\n","# Print assigned GPU\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","    print('and then re-execute this cell.')\n","else:\n","    print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUQcY5kdrWiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616090242296,"user_tz":420,"elapsed":16966,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"76fc75c8-9be1-473d-ee9a-21761efc257d"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUTMbgvwemkr"},"source":["# IMPORTANT: Ensure that the repository directory follows the path (or update all paths in the script):\n","# \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWlpeOl829ji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616091302204,"user_tz":420,"elapsed":524704,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"05824b2f-08a3-4abb-8ea9-6fbd70f7000e"},"source":["# Download dataset to pre-specified folder on local VM instance\n","%cd /content/\n","\n","import time\n","from datetime import datetime, timedelta\n","\n","start = time.time()\n","\n","!bash \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose/scripts/coco_dl.sh\" ./datasets\n","\n","download_time = time.time() - start\n","print(\"Total download time: {}\".format(str(timedelta(seconds=download_time))))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content\n","train2017.zip and train2017/ not found!\n","Downloading from... http://images.cocodataset.org/zips/train2017.zip\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 18.0G  100 18.0G    0     0  71.8M      0  0:04:16  0:04:16 --:--:-- 75.8M\n","Unzipping: train2017.zip\n","Deleting file: train2017.zip\n","val2017.zip and val2017/ not found!\n","Downloading from... http://images.cocodataset.org/zips/val2017.zip\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  777M  100  777M    0     0  55.9M      0  0:00:13  0:00:13 --:--:-- 55.8M\n","Unzipping: val2017.zip\n","Deleting file: val2017.zip\n","annotations_trainval2017.zip not found!\n","Downloading from... http://images.cocodataset.org/zips/annotations_trainval2017.zip\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  241M  100  241M    0     0  70.1M      0  0:00:03  0:00:03 --:--:-- 70.1M\n","Unzipping: annotations_trainval2017.zip\n","Deleting file: annotations_trainval2017.zip\n","stuff_annotations_trainval2017.zip not found!\n","Downloading from... http://images.cocodataset.org/zips/stuff_annotations_trainval2017.zip\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 1095M  100 1095M    0     0  47.5M      0  0:00:23  0:00:23 --:--:-- 46.8M\n","Unzipping: stuff_annotations_trainval2017.zip\n","Deleting file: stuff_annotations_trainval2017.zip\n","Total download time: 0:08:44.456308\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d514HD0J2xmy","executionInfo":{"status":"ok","timestamp":1616091312324,"user_tz":420,"elapsed":1062,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"a707ba5d-cb97-40a8-9220-91aeecf86ea9"},"source":["!ls /content/datasets/coco/train2017 | wc -l\n","!ls /content/datasets/coco/val2017 | wc -l"],"execution_count":12,"outputs":[{"output_type":"stream","text":["118287\n","5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SBQbXIcUC4sG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616091315543,"user_tz":420,"elapsed":352,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"1eacbd33-18e9-4c8b-eed4-83cfc574561b"},"source":["# Ensure that filesystem is set up correctly and will not be the bottleneck\n","import time\n","from datetime import datetime, timedelta\n","\n","start = time.time()\n","\n","import os\n","def print_files_in_dir(path):\n","    print(len(os.listdir(path)), \" files at \", path)\n","\n","print_files_in_dir('/content/datasets/coco/train2017/')\n","print_files_in_dir('/content/datasets/coco/val2017/')\n","\n","\n","setup_time = time.time() - start\n","print(\"Total setup time: {}\".format(str(timedelta(seconds=setup_time))))\n","\n","if setup_time > 1:\n","    print(\"There appears to be a bottleneck with filesystem loading time. This may severely impact training speed.\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["118287  files at  /content/datasets/coco/train2017/\n","5000  files at  /content/datasets/coco/val2017/\n","Total setup time: 0:00:00.076181\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeLJoy2iz5sE","executionInfo":{"status":"ok","timestamp":1616091318048,"user_tz":420,"elapsed":408,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"d07c9aec-905f-45eb-a072-ba13c793acc2"},"source":["# Change dir to project dir\n","%cd \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\"\n","\n","# Toggle COLAB_TRAINING variable in constants file\n","# https://askubuntu.com/questions/20414/find-and-replace-text-within-a-file-using-commands\n","!sed -i.bak 's/COLAB_TRAINING = False/COLAB_TRAINING = True/g' constants.py \n","\n","# Remove backup file\n","!rm constants.py.bak"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Y3o1VSmk_dE","executionInfo":{"status":"ok","timestamp":1616096545164,"user_tz":420,"elapsed":424,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"2cc41afa-ea3b-4f89-d24e-9457c159acf0"},"source":["!head train.py\n","!google-drive-ocamlfuse -cc \n","# refresh collab session with latest source files in GDrive\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","print(\"Tensorflow version \" + tf.__version__)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["import argparse\n","import os\n","import time\n","from datetime import datetime, timedelta\n","\n","import tensorflow as tf\n","from tensorflow.compat.v1.keras import backend as k\n","\n","from constants import *\n","from hourglass import HourglassNet\n","/bin/bash: google-drive-ocamlfuse: command not found\n","Tensorflow version 2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2MRZcYU2TN2","executionInfo":{"status":"ok","timestamp":1616096620243,"user_tz":420,"elapsed":72623,"user":{"displayName":"Julian Rocha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0QrES-WzNCHbIVd-DJKGaCtIC3OO5amuVSCFOPw=s64","userId":"17506259248702060718"}},"outputId":"653640aa-ff20-4abf-a745-76d3d3707abb"},"source":["!python3 train.py --epochs 100 --batch 128 --hourglass 4 --subset 1.0\n","\n","# To resume, uncomment the following and point it to the subdirectory. Ensure hourglass matches.\n","# !python3 train.py --epochs 100 --batch 12 --hourglass 4 --subset 1.0 --resume True --resume-subdir \"2021-03-13-16h-38m_batchsize_12_hg_4\" --resume-epoch 9\n","\n","# Note about subset: if you decide to run on a subset <1.0, there is no functionality to retrieve the same subset of data if the model is stopped then resumed. For this reason, subset should only be used for quick tests rather than reporting robust/repeatable results. "],"execution_count":48,"outputs":[{"output_type":"stream","text":["2021-03-18 19:42:28.020046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\n","\n","Setup start: Thu Mar 18 19:42:31 2021\n","\n","TensorFlow detected the following GPU(s):\n","2021-03-18 19:42:31.040130: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-18 19:42:31.041268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-03-18 19:42:31.052285: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-03-18 19:42:31.052339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5b007bb24136): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:From train.py:34: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n","\n","2021-03-18 19:42:31.053545: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","\n","\n","Training start: Thu Mar 18 19:42:31 2021\n","\n","Hourglass blocks:  4, epochs: 100, batch size: 128, subset: 1.00\n","2021-03-18 19:42:31.056809: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-18 19:42:31.057286: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-18 19:42:31.057702: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-18 19:42:31.062232: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.91.246.146:8470}\n","2021-03-18 19:42:31.062276: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31868}\n","2021-03-18 19:42:31.077955: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.91.246.146:8470}\n","2021-03-18 19:42:31.078036: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31868}\n","2021-03-18 19:42:31.080647: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:31868\n","All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n","loading annotations into memory...\n","Done (t=15.21s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.64s)\n","creating index...\n","index created!\n","Unfiltered df contains 273469 anns\n","Train/Val dfs contains 149813/6352 anns\n","Model save directory created: models/2021-03-18-19h-42m_batchsize_128_hg_4\n","2021-03-18 19:43:31.371767: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n","2021-03-18 19:43:31.371841: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n","2021-03-18 19:43:31.382458: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n","Model architecture json saved to: models/2021-03-18-19h-42m_batchsize_128_hg_4/hpe_hourglass_stacks_04_batchsize_128.json\n","Model checkpoints saved to: models/2021-03-18-19h-42m_batchsize_128_hg_4/hpe_epoch{epoch:02d}_val_loss_{val_loss:.4f}_train_loss_{loss:.4f}.hdf5\n","Traceback (most recent call last):\n","  File \"train.py\", line 119, in <module>\n","    hgnet.train(args.batch, args.model_save, args.epochs, args.subset)\n","  File \"/content/gdrive/My Drive/Colab Data/COCO-Human-Pose/hourglass.py\", line 98, in train\n","    self._start_train(batch_size=batch_size, model_base_dir=model_save_base_dir, epochs=epochs, initial_epoch=0, model_subdir=model_subdir, current_time=current_time, subset=subset)\n","  File \"/content/gdrive/My Drive/Colab Data/COCO-Human-Pose/hourglass.py\", line 91, in _start_train\n","    validation_steps=len(val_generator), epochs=epochs, initial_epoch=initial_epoch, callbacks=callbacks)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1075, in fit\n","    steps=data_handler.inferred_steps)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 231, in __init__\n","    self.set_model(model)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 286, in set_model\n","    callback.set_model(model)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 2122, in set_model\n","    self._write_keras_model_summary()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 2167, in _write_keras_model_summary\n","    summary_ops_v2.keras_model('keras', self.model, step=0)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/summary_ops_v2.py\", line 1249, in keras_model\n","    metadata=summary_metadata)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/summary_ops_v2.py\", line 775, in write\n","    _should_record_summaries_v2(), record, _nothing, name=\"summary_cond\")\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\", line 51, in smart_cond\n","    pred_value = smart_constant_value(pred)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\", line 79, in smart_constant_value\n","    pred_value = c_api.TF_TryEvaluateConstant_wrapper(pred.graph._c_graph,\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in graph\n","    \"Tensor.graph is meaningless when eager execution is enabled.\")\n","AttributeError: Tensor.graph is meaningless when eager execution is enabled.\n","Error in atexit._run_exitfuncs:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\", line 738, in async_wait\n","    context.async_wait()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 2330, in async_wait\n","    context().sync_executors()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 645, in sync_executors\n","    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)\n","tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme '[local]' not implemented (file: 'logs/2021-03-18-19h-42m_batchsize_128_hg_4/train')\n","\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.\n","2021-03-18 19:43:37.077590: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 31236, Output num: 0\n","Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",":{\"created\":\"@1616096617.074268768\",\"description\":\"Error received from peer ipv4:10.91.246.146:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 31236, Output num: 0\",\"grpc_status\":3}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cMVxhYe7zSKU"},"source":[""],"execution_count":null,"outputs":[]}]}