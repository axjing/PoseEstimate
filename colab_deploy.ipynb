{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_deploy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFeykNVVibs4"
      },
      "source": [
        "# Set TensorFlow version to 1.x\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Print assigned GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUQcY5kdrWiO"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLTBd45GibtD"
      },
      "source": [
        "!pip install streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "\n",
        "# IMPORTANT: Ensure that the repository directory follows the path:\n",
        "# \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f-M0Kl0Zpmf"
      },
      "source": [
        "%cd \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\"\n",
        "!streamlit run human_pose_app.py &>/dev/null&\n",
        "!npx localtunnel --port 8501 --subdomain 'coco-human-pose'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWlpeOl829ji"
      },
      "source": [
        "# Download dataset to pre-specified folder on local VM instance\n",
        "# Change dir to project dir\n",
        "%cd \"/content/gdrive/MyDrive/Colab Data/COCO-Human-Pose\"\n",
        "\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "!bash \"./scripts/coco_dl.sh\" /content/datasets\n",
        "\n",
        "download_time = time.time() - start\n",
        "print(\"Total download time: {}\".format(str(timedelta(seconds=download_time))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d514HD0J2xmy"
      },
      "source": [
        "!ls /content/datasets/coco/train2017 | wc -l\n",
        "!ls /content/datasets/coco/val2017 | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBQbXIcUC4sG"
      },
      "source": [
        "# Ensure that filesystem is set up correctly and will not be the bottleneck\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "import os\n",
        "def print_files_in_dir(path):\n",
        "    print(len(os.listdir(path)), \" files at \", path)\n",
        "\n",
        "print_files_in_dir('/content/datasets/coco/train2017/')\n",
        "print_files_in_dir('/content/datasets/coco/val2017/')\n",
        "\n",
        "\n",
        "setup_time = time.time() - start\n",
        "print(\"Total setup time: {}\".format(str(timedelta(seconds=setup_time))))\n",
        "\n",
        "if setup_time > 1:\n",
        "    print(\"There appears to be a bottleneck with filesystem loading time. This may severely impact training speed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeLJoy2iz5sE"
      },
      "source": [
        "# Toggle COLAB_TRAINING variable in constants file\n",
        "# https://askubuntu.com/questions/20414/find-and-replace-text-within-a-file-using-commands\n",
        "!sed -i.bak 's/COLAB_TRAINING = False/COLAB_TRAINING = True/g' constants.py \n",
        "\n",
        "# Remove backup file\n",
        "!rm constants.py.bak\n",
        "\n",
        "# Upgrade required imgaug package because of a bug on 0.2.9\n",
        "!pip install --upgrade imgaug==0.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2MRZcYU2TN2"
      },
      "source": [
        "!python3 train.py --epochs 100 --batch 12 --hourglass 4 --subset 1.0 --loss \"weighted_mse\" --augment \"none\" --notes \"sigma4\"\n",
        "\n",
        "# To resume, add the following to the above command, and point it to the subdirectory of the model checkpoints. Ensure everything matches\n",
        "# --resume True --resume-epoch 15 --resume-subdir \"2021-03-13-16h-38m_batchsize_12_hg_4\"\n",
        "\n",
        "# Note about subset: if you decide to run on a subset <1.0, there is no functionality to retrieve the same subset of data if the model is stopped then resumed. For this reason, subset should only be used for quick tests rather than reporting robust/repeatable results. \n",
        "\n",
        "# Note about loss function and augmentation: Ensure that they match across training sessions"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}